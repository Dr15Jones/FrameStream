// -*- C++ -*-
//
// Package:     JobControl
// Module:      FileCommand
//
//   See HelpMessage below for description!
//
// Implimentation:
//     <Notes on implimentation>
//
// Author:      Martin Lohner
// Created:     Tue Aug 19 23:35:15 EST 1997
// $Id: FileCommand.cc,v 1.27 2003/10/21 15:09:27 cdj Exp $
//
// Revision history at end of file
//

#include "Experiment/Experiment.h"

// system include files
#if defined(STL_TEMPLATE_DEFAULT_PARAMS_FIRST_BUG)
#include <set>
#endif /* STL_TEMPLATE_DEFAULT_PARAMS_FIRST_BUG */

// user include files
#include "Experiment/report.h"
#include "JobControl/FileCommand.h"
#include "JobControl/FileModule.h"
#include "JobControl/JobControl.h"
#include "DataHandler/StreamSet.h"
#include "DAException/DAException.h"
#include "DataHandler/DataKey.h"

// STL classes
#include <set>
#include <algorithm>

//
// constants, enums and typedefs
//
static const char* const kFacilityString = "JobControl.FileCommand";
 
const string helpMessage = 
string( "// Description: FileCommand                                       \n" )+
string( "//                                                                \n" )+
string( "// Valid subcommands are:                                         \n" )+
string( "//                  (<src>=sourcename, <snk>=sinkname,strm=stream)\n" )+
string( "//                                                                \n" )+
string( "//  file help                           see this help page        \n" )+
string( "//                                                                \n" )+
string( "//  file source <src> [<strm1>..]       define src w/ strms       \n" )+
string( "//  file src <src> [<strm1>..]          synonym for \"source\"    \n" )+
string( "//  file use <src> [<strm1>..]          synonym for \"source\"    \n" )+
string( "//  file input <src> [<strm1>..]        synonym for \"source\"    \n" )+
string( "//  file in  <src> [<strm1>..]          synonym for \"source\"    \n" )+
string( "//                                                                \n" )+
string( "//  file add <token> <src> [<strm1>..]  add src to <token>        \n" )+
string( "//                                                                \n" )+
string( "//  file sink   <snk> <strm1> [strm2..] define sink w/ strms      \n" )+
string( "//  file output <snk> <strm1> [strm2..] synonym for \"sink\"      \n" )+
string( "//  file out    <snk> <strm1> [strm2..] synonym for \"sink\"      \n" )+
string( "//    if format supports specifying data to (not) write           \n" )+
string( "//  file sink   <snk> {<strm1> [exclude] { [datatags] } }         \n" )+
string( "//    where [datatags] must be enclosed in {} if specifying       \n" )+
string( "//    usage and/or production tags                                \n" )+
string( "//                                                                \n" )+
string( "//  1.) ----------- Sources ----------------                      \n" )+
string( "//  To define an input source, use the \"source\" command;        \n" )+
string( "//  the system will return a \"token\" which has to be used       \n" )+
string( "//  to add new sources to the \"chain\" with name \"token\".      \n" )+
string( "//                                                                \n" )+
string( "//  You can also create your own token or rename the token        \n" )+
string( "//  generated by the system via the \"source\" command;           \n" )+
string( "//  Please see the help page for the \"source\" command           \n" )+
string( "//  for details.                                                  \n" )+
string( "//                                                                \n" )+
string( "//  Example:                                                      \n" )+
string( "//  i.)  suez> source create myFirstChain                         \n" )+
string( "//       suez> file add myFirstChain file1.rp                     \n" )+
string( "//       suez> file add myFirstChain file2.rp                     \n" )+
string( "//                                                                \n" )+
string( "//  OR                                                            \n" )+
string( "//  ii.) suez> file src file1.rp                                  \n" )+
string( "//        new token \"T_file1\"                                   \n" )+
string( "//       suez> source rename T_file1 chain1                       \n" )+
string( "//       suez> file add chain1 file2.rp                           \n" )+
string( "//       suez> file add chain1 file1.rp                           \n" )+
string( "//                                                                \n" )+
string( "//  If you don't like the tokens returned by Suez, and you don't  \n" )+
string( "//  feel like using example i.) above, you may use the one-liner  \n" )+
string( "//                                                                \n" )+
string( "//       suez> file add mysource myfile event                     \n" )+
string( "//                                                                \n" )+
string( "//  which uses the token \"mysource\". (if not used before!)      \n" )+
string( "//  (The \"add\" command is normally used for chaining files,     \n" )+
string( "//   but the chaining only happens when the second (!) file       \n" )+
string( "//   is added, so this trick will always work.)                   \n" )+
string( "//                                                                \n" )+
string( "//  One more trick: the token returned by Suez is available via   \n" )+
string( "//  the command-line interpreter:                                 \n" )+
string( "//                                                                \n" )+
string( "//       suez> set sourceName [file src file1.rp]                 \n" )+
string( "//       suez> echo \"Using $sourceName\"                         \n" )+
string( "//                                                                \n" )+
string( "//  2.) ------------ Sinks -------------------                    \n" )+
string( "//  To define an output sink, use the \"sink\" command.           \n" )+
string( "//                                                                \n" )+
string( "//  Examples:                                                     \n" )+
string( "//       suez> file sink outputFile.pds event                     \n" )+
string( "//       suez> file sink outputFile.pds {event {}}                \n" )+
string( "//       suez> file sink outputFile.pds {event {DBEventHeader}}   \n" )+
string( "//       suez> file sink outputFile.pds {event { {DBEventHeader Mine}}}\n" )+
string( "//       suez> file sink outputFile.pds {event { {DBEventHeader {} Mine}}}\n" )+
string( "//       suez> file sink outputFile.pds {event exclude {DBEventHeader}}\n" )+
string( "//                                                                \n" )+
string( "//                                                                \n" )+
string( "// Some standard streams are:                                     \n" )+
string( "//                        beginrun endrun event                   \n" )+
string( "//                        geometry hardware user                  \n" )+
string( "//                                                                \n" )+
string( "// If no streams are specified, default streams based on          \n" )+
string( "// the source format are used.                                    \n" );

//
// static data member definitions
//

//
// constructors and destructor
//
FileCommand::FileCommand( const Command::Name& name,
			  Module* target )
   : Command( name, target, false )
{
}

// FileCommand::FileCommand( const FileCommand& )
// {
// }

FileCommand::~FileCommand()
{
}

//
// assignment operators
//
// const FileCommand& FileCommand::operator=( const FileCommand& )
// {
// }

//
// member functions
//
int
FileCommand::execute( int argc, char* argv[] )
{
   int result = COMMAND_ERROR;

   setArgs( argc, argv );
   if ( 2 <= argc ) {
      if( 0 == strcmp( argv[1], "help" ) ) {
	 result = helpHandler();
      } else 
      if( 0 == strcmp( argv[1], "source" ) ) {
	 result = sourceHandler();
      } else 
      if( 0 == strcmp( argv[1], "src" ) ) {
	 result = sourceHandler();
      } else 
      if( 0 == strcmp( argv[1], "use" ) ) {
	 result = sourceHandler();
      } else 
      if( 0 == strcmp( argv[1], "input" ) ) {
	 result = sourceHandler();
      } else 
      if( 0 == strcmp( argv[1], "in" ) ) {
	 result = sourceHandler();
      } else 
      if( 0 == strcmp( argv[1], "add" ) ) {
	 result = addHandler();
      } else
      if( 0 == strcmp( argv[1], "sink" ) ) {
	 result = sinkHandler();
      } else
      if( 0 == strcmp( argv[1], "output" ) ) {
	 result = sinkHandler();
      } else
      if( 0 == strcmp( argv[1], "out" ) ) {
	 result = sinkHandler();
      }
      else 
      {
	 report( SYSTEM, kFacilityString ) << "invalid command arg" << endl;
	 helpHandler();
	 result = COMMAND_ERROR;
      }
   } 
   else {
      report( SYSTEM, kFacilityString ) << "wrong # args" << endl;
      helpHandler();
      result = COMMAND_ERROR;
   }

   return result;
}

int
FileCommand::helpHandler()
{
   // print help from ModuleCommand.h header
   report( SYSTEM, kFacilityString ) << "\n" << helpMessage << endl;

   return COMMAND_OK;
}

int
FileCommand::sourceHandler( )
{
   int result = COMMAND_ERROR;
   string resultString;

   FileModule* fileInput = (FileModule*)target();

   // expect 3 or more arguments!
   // eg. "fileinput add <filename> <stream1> [<stream2> etc.]"
   if ( m_argc < 3 ) // wrong number of arguments
   {
      report( SYSTEM, kFacilityString ) << "wrong # args" << endl;
      result = COMMAND_ERROR;
   } 
   else
   {
      // first the sourceName
      string sourceName( getArgument( 2 ) );

      // checkIfSourceExists will give back valid name, if given bad one.
      DABoolean sourceExists = fileInput->checkIfSourceExists( sourceName );
      if( ! sourceExists ) // if we don't have a source
      {
	 report( SYSTEM, kFacilityString ) 
	    << "Input Source non-existent: \"" << sourceName << "\"." << endl;
	 result = COMMAND_ERROR;
      }
      else 
      {  // after we have established a valid source, now get the read streams
	 StreamSet readStreams;
	 parseStreams( readStreams, 3 );

	 // finally add source to system
	 string ioToken;
	 fileInput->addSource( sourceName, readStreams, ioToken );
	 resultString += ioToken;

	 // everything's fine
	 result = COMMAND_OK;
      } 
   }

   setResult( resultString );

   return result;
}

int
FileCommand::addHandler( )
{
   int result = COMMAND_ERROR;
   string resultString;

   FileModule* fileInput = (FileModule*)target();

   // expect 4 arguments (if more --> streams will be ignored)
   // eg. "fileinput add <token> <filename>]"
   if ( m_argc < 4 ) // wrong number of arguments
   {
      report( SYSTEM, kFacilityString ) << "wrong # args" << endl;
      result = COMMAND_ERROR;
   } 
   else
   {
      // first the token name
      string token( getArgument( 2 ) );

      // first the sourceName
      string sourceName( getArgument( 3 ) );

      // checkIfSourceExists will give back valid name, if given bad one.
      DABoolean sourceExists = fileInput->checkIfSourceExists( sourceName );
      if( ! sourceExists ) // if we don't have a source
      {
	 report( SYSTEM, kFacilityString ) 
	    << "Input Source non-existent: \"" << sourceName << "\"." << endl;
	 result = COMMAND_ERROR;
      }
      else 
      {  // after we have established a valid source, now get the read streams
	 StreamSet readStreams;
	 parseStreams( readStreams, 4 );

	 // finally add source to system
	 fileInput->addSource( sourceName, readStreams, token );
	 resultString += token;

	 // everything's fine
	 result = COMMAND_OK;
      } 
   }

   setResult( resultString );
   return result;
}

int
FileCommand::sinkHandler( )
{
   int result = COMMAND_ERROR;

   FileModule* fileOutput = (FileModule*)target();

   // expect 3 or more arguments!
   // eg. "fileoutput add <filename> <stream1> [<stream2> etc.]"
   if ( m_argc < 4 ) // wrong number of arguments
   {
      report( SYSTEM, kFacilityString ) << "wrong # args" << endl;
      result = COMMAND_ERROR;
   } 
   else
   {
      // first the sinkName
      string sinkName( getArgument( 2 ) );

      // checkIfSinkExists will give back valid name, if given bad one 
      // by asking User for feed-back (either new Name or give up)
      DABoolean goodSinkName = fileOutput->checkSinkName( sinkName );
      if( ! goodSinkName ) // if sinkName is not good 
      {
	 report( SYSTEM, kFacilityString ) 
	    << "Invalid sinkName: " << sinkName << "." << endl;
	 result = COMMAND_ERROR;
      }
      else 
      {  // after we have established a valid sink, now get the write streams
	 StreamToDataStringTagsToStoreMap writeStreamsAndData;
	 
         try {
	    parseStreamsAndData( writeStreamsAndData, 3 );
         } catch( const DAException& iException ) {
	    report( SYSTEM, kFacilityString ) 
	       << "Problem parsing stream/data info:\n" << iException.what()<<endl;
         	return COMMAND_ERROR;
         }
	 // if no streams specified, give warning 
	 // that will default to active streams
	 if( 0 == writeStreamsAndData.size() ) 
	 {
	    report( SYSTEM, kFacilityString )
	       << "Need to specify output streams!" 
	       << endl;
	    result = COMMAND_ERROR;
	 }
	 else
	 {
            //See if we are supposed to store all data for each stream
            // and build list of streams
            DABoolean storeAllData = true;
       
            StreamSet writeStreams;
	    StreamToDataStringTagsToStoreMap::iterator itEnd = writeStreamsAndData.end();
	    for( StreamToDataStringTagsToStoreMap::iterator itStreamData = writeStreamsAndData.begin();
	         itStreamData != itEnd;
	         ++itStreamData) 
	    {
	    	writeStreams.insert( (*itStreamData).first ) ;
	    	
	    	if( (*itStreamData).second.storeThese() ) {
	    		storeAllData = false;
	    	} else {
	    	  if( (*itStreamData).second().size() != 0 ) {
	    	     storeAllData = false;
	          }
	    	}
	    }
	    
	    if( storeAllData ) {
	      // finally add sink to system
	      fileOutput->addSink( sinkName, writeStreams );
	    } else {
               fileOutput->addSink( sinkName, writeStreams, writeStreamsAndData );
	    }
//	    {
//	    StreamToDataStringTagsToStoreMap::iterator itEnd = writeStreamsAndData.end();
//	    for( StreamToDataStringTagsToStoreMap::iterator itStreamData = writeStreamsAndData.begin();
//	         itStreamData != itEnd;
//	         ++itStreamData) 
//	    {
//	    	 cout <<"stream "<< (*itStreamData).first.value() <<endl;
//	    	 if( (*itStreamData).second.storeThese() ) {
//	    	 	cout <<" store"<<endl;
//	    	 } else {
//	    	 	cout <<" do not store"<<endl;
//	    	 }
//	    	 DataStringTagsToStore::iterator itDataEnd = (*itStreamData).second().end();
//          for( DataStringTagsToStore::iterator itData = (*itStreamData).second().begin();
//               itData != itDataEnd;
//               ++itData ) {
//             cout <<"  \""<< (*itData).type() <<"\" \""<<(*itData).usage()
//             <<"\" \"" << (*itData).production() <<"\""<<endl;
//          }
//	    }
//	    }
	    // everything's fine
	    result = COMMAND_OK;
	 }

      } // valid sink name
   } // proper number of arguments

   return result;
}

//
// const member functions
//

static const char* kWhiteSpace =" \n\t";

static
void
parseTags( DataStringTagsToStore::Tags& iTags, const char* iTagString)
{
   static string kDoubleQuote("\"");
   string missingTags;
   
   string tagString( iTagString);
   
   string::size_type index = 0;
   string::size_type lastNonSpace = tagString.find_last_not_of(kWhiteSpace);
   while( index < lastNonSpace )
   {
     	
   	//see if the datatype has a '{' as part of its definition
   	string::size_type braceIndex = tagString.find_first_of("{", index);
   	string::size_type nonBraceIndex = tagString.find_first_not_of(" \n\t{",index);
   	
      if( braceIndex < nonBraceIndex ) {
      	//find matching closing brace
      	string::size_type closeBraceIndex = tagString.find("}", index);
	string::size_type subBraceIndex = tagString.find("{",braceIndex+1);
	unsigned int braceLevel = 1;
	do {
	   if( subBraceIndex < closeBraceIndex ) {
	      ++braceLevel;
	      subBraceIndex = tagString.find("{",subBraceIndex+1);
	   } else if (subBraceIndex == closeBraceIndex ) {
	      //have a problem
	      braceLevel = 0;
	   } else {
	      --braceLevel;
	      if (braceLevel > 0 ) {
		 closeBraceIndex = tagString.find("}",closeBraceIndex+1);
	      }
	   }
	} while( braceLevel > 0 );

      	if( closeBraceIndex == string::npos ) {
      	  //missing closeBrace
      	  report(ERROR, kFacilityString) <<" missing closing brace for \""
					 << string( iTagString, braceIndex)
					 << "\""<<endl;
      	  throw DAException("missing closing brace");
      	}
      	//look for all three types
      	string::size_type firstIndex = tagString.find_first_not_of(kWhiteSpace, 
      	   braceIndex+1);
      	string typeTag, usageTag, productionTag;
      	
      	if( closeBraceIndex > firstIndex ) {
      	   string::size_type lastIndex = tagString.find_first_of(" \n\t}", firstIndex);
      	   typeTag = string(tagString, firstIndex, lastIndex-firstIndex);
      		
      	   if (typeTag.size() == 0 ) {
      	      index = lastIndex + 1;
      	      continue;
      	   }
      	   //see if this is a known type 
      	   if(TypeTag::kDefaultValue== TypeTag::findType(typeTag).value() ) {
      	       missingTags += kDoubleQuote + typeTag + kDoubleQuote + "\n";
      	   }
      	   if( lastIndex != closeBraceIndex ) {
      	     firstIndex = tagString.find_first_not_of(kWhiteSpace, lastIndex);
	     if ('{' == tagString[firstIndex] ) {
		++firstIndex;
	     }
      	     if(firstIndex != closeBraceIndex ) {
      	        lastIndex = tagString.find_first_of(" \n\t}", firstIndex );
      	        usageTag = string(tagString, firstIndex, lastIndex-firstIndex);
      				
      		if(lastIndex != closeBraceIndex ) {
		   if ('}' == tagString[lastIndex] ) {
		      ++lastIndex;
		   }
      		   firstIndex = tagString.find_first_not_of(kWhiteSpace, lastIndex);
      		   if(firstIndex != closeBraceIndex ) {
      		      lastIndex = tagString.find_first_of(" \n\t}", firstIndex );
      		      productionTag = string(tagString, firstIndex, lastIndex-firstIndex);
		      //see if there are more items in this list
		      if( lastIndex != closeBraceIndex ) {
			 if( closeBraceIndex != tagString.find_first_not_of(kWhiteSpace, lastIndex+1) ) {
			    throw DAException( (string("greater than 3 arguments for data specification: \"")+tagString+"\"").c_str() );
			 }
		      }
      		   }
      		}
      	     }
      	   }
      	   index = tagString.find_first_of("}",lastIndex);
           iTags.insert( 
               DataStringTagsToStore::DatumStringTags(typeTag, usageTag, productionTag) );
      	}
      } else if( nonBraceIndex != string::npos ) {
      	string::size_type lastIndex = tagString.find_first_of(" \n\t{}",nonBraceIndex);
      	string typeTag( tagString, nonBraceIndex, lastIndex-nonBraceIndex );
         
        if(typeTag.size() != 0 ) {
      	   //see if this is a known type 
      	   if(TypeTag::kDefaultValue== TypeTag::findType(typeTag).value() ) {
      	       missingTags += kDoubleQuote + typeTag + kDoubleQuote + "\n";
      	   }
            iTags.insert( 
               DataStringTagsToStore::DatumStringTags(typeTag, string(), string()) );
         }
         index = lastIndex +1;
      } else {
      	//done parsing since found nothing that wasn't a space
         index = tagString.size();
      }
   }

   if( missingTags.size() != 0 ) 
   {
      report(WARNING, kFacilityString) 
   	<<"\n The following types are unknown, please check spelling\n"<<missingTags<<endl;
   }
}

void
FileCommand::parseStreamsAndData( StreamToDataStringTagsToStoreMap& iMap,
                                  int index ) const
{
   const char* arg;
   
   while( 0 != ( arg = getArgument( index++) ) )
   {
      //see if there is a '{' since that signals specification
      // of exactly what is to be stored
      string argument( arg);

      //get rid of any leading white space
      string::size_type startOfArg = argument.find_first_not_of(kWhiteSpace);
      if( startOfArg != 0 ) {
	 argument = string(arg, startOfArg, argument.size() );
      }
      string::size_type endOfStreamPos = argument.find_first_of("{ ");
      string::size_type firstBrace = argument.find_first_of("{");
      if( string::npos != firstBrace ) 
      {
      	//do we have equal numbers of '{' and '}'?
      	unsigned int nOpen = 0;
	unsigned int nClose = 0;
#if !defined(NO_ITERATOR_TRAITS_BUG)
      	if( (nOpen = count( argument.begin(), argument.end(), '{') ) !=
      	    (nClose = count(argument.begin(), argument.end(), '}') ) ) {
#else
	count( argument.begin(), argument.end(), '{', nOpen) ;
	count(argument.begin(), argument.end(), '}', nClose);
      	if( nOpen != nClose ) {
#endif
           if( nOpen > nClose ) {
      	       report(ERROR, kFacilityString) <<"more { than } in \""<<argument<<"\"\n"<<endl;
           } else {
      	       report(ERROR, kFacilityString) <<"more } than { in \""<<argument<<"\"\n"<<endl;
           }
           throw DAException("unbalanced braces");
      	}
      	
      	//find stream
         string streamName( arg,startOfArg, endOfStreamPos);
	 
         Stream::Type newStreamType = StreamType( streamName.c_str() );
         if( true != newStreamType.isStandard() ) 
         {
            report( WARNING, kFacilityString )
	         << "Using non-standard Stream type!" << arg << "." << endl;
         }

         string::size_type beginOfDataPos = endOfStreamPos;
         //see if we have the qualifier 'exclude'
         DABoolean inclusiveList = true;
         string::size_type firstNonSpace = argument.find_first_not_of(kWhiteSpace, endOfStreamPos);
         if( '{' != argument[firstNonSpace] ) {
            const string excludeKeyWord("exclude");
            if( excludeKeyWord == argument.substr(firstNonSpace, excludeKeyWord.size() ) ) {
            	inclusiveList = false;
               string::size_type endOfQualifier = argument.find_first_of("{",firstNonSpace);
               beginOfDataPos = endOfQualifier;
            } else {
               string::size_type endOfQualifier = argument.find_first_of("{",firstNonSpace);
               report( ERROR, kFacilityString) <<"qualifier \""
                   << argument.substr(firstNonSpace, endOfQualifier-firstNonSpace)
                   <<"\" not allowed \n  only \"exclude\" is allowed" <<endl;
               throw DAException("Bad qualifier");
            }
         }
   	 DataStringTagsToStore::Tags tags;
	 //need to be careful to not get rid of TWO {'s in a row
         string::size_type dataStart = argument.find_first_not_of(kWhiteSpace, beginOfDataPos);
	 if( '{' == argument[dataStart] ) {
	    ++dataStart;
	    dataStart = argument.find_first_not_of(kWhiteSpace, dataStart);
	 }
         
   	 parseTags( tags, arg+dataStart );
   		
   	 iMap.insert( make_pair( newStreamType, 
   		                        DataStringTagsToStore(tags, inclusiveList ) ) );
      } else {
         //it's just the stream name
         Stream::Type newStreamType = StreamType( arg );
         if( true != newStreamType.isStandard() ) 
         {
	    report( WARNING, kFacilityString )
	         << "Using non-standard Stream type!" << arg << "." << endl;
         }
         //tell it exclude nothing (i.e. store everything)
         iMap.insert( make_pair( newStreamType,
            DataStringTagsToStore( DataStringTagsToStore::Tags(), false) ) ); 
      }
   }
}

void
FileCommand::parseStreams( StreamSet& readStreams, int index ) const
{
   const char* arg;
   while ( 0 != ( arg = getArgument( index++ ) ) ) 
   {
      // check if stream string is non-standard --> issue warning
      // (this is a good idea, because the user might have 
      // mistyped the stream name
      Stream::Type newStreamType = StreamType( arg );
      if( true != newStreamType.isStandard() ) 
      {
	 report( WARNING, kFacilityString )
	    << "Using non-standard Stream type!" << arg << "." << endl;
      }
      readStreams.add( newStreamType );
   }
}

//
// static member functions
//


// Revision history
//
// $Log: FileCommand.cc,v $
// Revision 1.27  2003/10/21 15:09:27  cdj
// fixed 'file out' command to be able to handle a default usage tag when specifying a production tag
//
// Revision 1.26  2002/04/22 19:17:12  cdj
// improved parsing of what data should be stored in a sink
//
// Revision 1.25  2001/12/18 21:25:53  cdj
// made the parser for data types to store more robust
//
// Revision 1.24  2001/10/22 14:18:09  cdj
// fixed bug that caused writeout parsing to fail if first item had a usage tag
//
// Revision 1.23  2001/10/05 00:42:13  cdj
// fixed bug on Solaris that caused false error when specifying what to write out
//
// Revision 1.22  2001/09/07 17:01:08  cleo3
// handle using old version of count
//
// Revision 1.21  2001/06/15 21:06:21  cdj
// can now specify data (not) to store in a sink
//
// Revision 1.20  2000/06/01 17:48:43  mkl
// switch all Suez messages to SYSTEM level
//
// Revision 1.19  1999/06/18 03:03:53  mkl
// updated FileCommand help page
//
// Revision 1.18  1999/06/14 15:55:43  mkl
// return token name as tcl resultString
//
// Revision 1.17  1999/06/12 00:03:58  mkl
// allow to specify default streams per source format
//
// Revision 1.16  1999/03/11 22:02:38  mkl
// source out stream will activate stream; turn off superfluous warning for 'param' command
//
// Revision 1.15  1999/02/22 23:41:36  mkl
// setResult( string ) insteadof report in Commands; added NamingService and DefaultModule; fixed bug in stream command
//
// Revision 1.14  1998/11/09 19:33:06  mkl
// revamped Module/Command system to allow uniform loading of source/sink-formats, modules, processors/producers
//
// Revision 1.13  1998/07/28 15:53:14  mkl
// ripple effect: needed to include set
//
// Revision 1.12  1997/10/20 17:11:04  mkl
// fix for sink with unspecified streams
//
// Revision 1.11  1997/10/07 19:25:13  mkl
// cout --> report( INFO ) and kFacilityString update
//
// Revision 1.10  1997/10/07 04:19:01  mkl
// report --> cout for INFO messages
//
// Revision 1.9  1997/09/18 21:26:47  cdj
// changed Boolean to DABoolean
//
// Revision 1.8  1997/09/10 01:52:29  mkl
// replaced \n by end
//
// Revision 1.7  1997/09/05 02:35:58  mkl
// tried to unify error handling with tcl way
//
// Revision 1.6  1997/09/03 05:57:43  mkl
// moved from 'const string kFacilityString' to 'static const char* const'
//
// Revision 1.5  1997/09/03 02:38:39  mkl
// restructuring suez libraries
//
// Revision 1.4  1997/08/29 04:21:49  mkl
// simplify JobControl: remove FileInput/Output files, bug flag changes, handling of suffix .gz etc.
//
// Revision 1.3  1997/08/22 04:21:47  mkl
// standardize error messages from commands
//
// Revision 1.2  1997/08/20 07:27:16  mkl
// minor fixes to make cxx5.4-6 happy
//
// Revision 1.1  1997/08/20 06:23:31  mkl
// symmetrized sinks with sources in terms of user interface
//
